{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 앙상블: Boosting\n",
    "\n",
    "1. XGboost를 적용해본다.\n",
    "2. 다른 알고리즘들과 성능을 비교해본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'Python 3 (ipykernel) (복습_조현한_1287_260122.ipynb)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. Unable to get resolved server information for google.colab:colab:943f2dfe-6313-4172-bee8-39cf9a340f43"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 데이터 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mobile data\n",
    "path = \"https://raw.githubusercontent.com/DA4BAM/dataset/master/mobile_cust_churn.csv\"\n",
    "data = pd.read_csv(path)\n",
    "data.drop(['id', 'REPORTED_USAGE_LEVEL','OVER_15MINS_CALLS_PER_MONTH'], axis = 1, inplace = True)\n",
    "data.rename(columns = {'HANDSET_PRICE':'H_PRICE',\n",
    "                       'AVERAGE_CALL_DURATION':'DURATION',\n",
    "                       'REPORTED_SATISFACTION':'SATISFACTION',\n",
    "                       'CONSIDERING_CHANGE_OF_PLAN':'CHANGE'}\n",
    "            , inplace = True)\n",
    "data['CHURN'] = np.where(data['CHURN'] == 'LEAVE', 1, 0)  # XGBoost는 Label이 1,0 이어야 함\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 변수 명 | 내용 | 구분 |\n",
    "|----|----|----|\n",
    "| COLLEGE | 대학졸업 여부(1,0) - 범주 | |\n",
    "| INCOME | 연 수입액(달러) | |\n",
    "| OVERAGE | 월 초과사용 시간(분) | |\n",
    "| LEFTOVER | 월 사용 잔여시간비율(%) | |\n",
    "| HOUSE | 집 가격(달러) | |\n",
    "| HANDSET_PRICE | 핸드폰 가격(달러) | |\n",
    "| AVERAGE_CALL_DURATION | 평균 통화시간(분) | |\n",
    "| REPORTED_SATISFACTION | 만족도 설문('very_unsat', 'unsat', 'avg', 'sat', 'very_sat' ) - 범주 | |\n",
    "| CONSIDERING_CHANGE_OF_PLAN | 변경 계획 설문('never_thought', 'no', 'perhaps', 'considering', 'actively_looking_into_it') - 범주 | |\n",
    "| **CHURN** | 이탈여부(1 : 이탈, 0 : 잔류) | **Target** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터분할1\n",
    "target = 'CHURN'\n",
    "x = data.drop(target, axis=1)\n",
    "y = data.loc[:, target]\n",
    "\n",
    "# 가변수화\n",
    "dumm_cols = ['SATISFACTION','CHANGE']\n",
    "x = pd.get_dummies(x, columns = dumm_cols, drop_first = True)\n",
    "\n",
    "# 데이터 분할2\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=.5, random_state = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 모델링\n",
    "* Boosting 원리를 이용한 알고리즘 : XGB, LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 함수 불러오기\n",
    "from xgboost import XGBClassifier, plot_tree\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) 모델 선언\n",
    "model = XGBClassifier(n_estimators = 5, max_depth = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) 학습\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) 예측\n",
    "pred = model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) 평가\n",
    "print(classification_report(y_val, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. XGBoost에 대해서...\n",
    "\n",
    "### 1) 모델 시각화\n",
    "xgboost 자체 plot_tree 함수를 제공합니다.\n",
    "* `plot_tree(model, num_trees = 0)`\n",
    "    * num_trees : 전체 트리 5개짜리 모델이므로 각각 0~4까지 인덱스로 조회해 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 20,20  # 그래프 크기 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(model, num_trees = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(model, num_trees = 4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 변수 중요도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 중요도\n",
    "print(x_train.columns)\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 변수중요도 그래프 그리기 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(importance, names):\n",
    "    feature_importance = np.array(importance)\n",
    "    feature_names = np.array(names)\n",
    "\n",
    "    data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "    fi_df = pd.DataFrame(data)\n",
    "\n",
    "    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "    fi_df.reset_index(drop=True, inplace = True)\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.barplot(x='feature_importance', y='feature_names', data = fi_df)\n",
    "\n",
    "    plt.xlabel('FEATURE IMPORTANCE')\n",
    "    plt.ylabel('FEATURE NAMES')\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(model.feature_importances_, x_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 하이퍼파라미터 변화에 따른 성능 추세\n",
    "\n",
    "### (1) n_estimators\n",
    "* 1~150까지 증가시켜가며 성능 추세 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = {'n_estimators':range(1,100,2)}\n",
    "model = XGBClassifier()\n",
    "model_gs = GridSearchCV(model, grid_param, cv = 5)\n",
    "model_gs.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(model_gs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 중에서 하이퍼파라미터 값에 따른 성능을 별도로 저장합시다.\n",
    "temp = result.loc[:, ['param_n_estimators','mean_test_score']]\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이를 차트로 그려봅시다.\n",
    "plt.figure(figsize = (8,6))\n",
    "sns.lineplot(x = 'param_n_estimators', y = 'mean_test_score', data = temp )\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) learning rate\n",
    "* 0.01 ~ 1까지 증가시켜가며 성능 추세 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = {'learning_rate': np.linspace(0.02, 1, 50)}\n",
    "model = XGBClassifier()\n",
    "model_gs = GridSearchCV(model, grid_param, cv = 5)\n",
    "model_gs.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(model_gs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 중에서 하이퍼파라미터 값에 따른 성능을 별도로 저장합시다.\n",
    "temp = result.loc[:, ['param_learning_rate','mean_test_score']]\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이를 차트로 그려봅시다.\n",
    "plt.figure(figsize = (8,6))\n",
    "sns.lineplot(x = 'param_learning_rate', y = 'mean_test_score', data = temp )\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) n_estimators + learning rate\n",
    "* 이번에는 두 하이퍼파라미터를 동시에 조절하며 추세를 살펴보겠습니다.\n",
    "* n_estimators : 10, 50, 100\n",
    "* learning_rate : 0.01 ~ 0.3까지 0.01씩 증가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = {'learning_rate':np.linspace(0.01,0.3,30),\n",
    "              'n_estimators':[10,50,100]}\n",
    "model = XGBClassifier()\n",
    "model_gs = GridSearchCV(model, grid_param, cv = 5)\n",
    "model_gs.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(model_gs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 중에서 하이퍼파라미터 값에 따른 성능을 별도로 저장합시다.\n",
    "temp = result.loc[:, ['param_n_estimators', 'param_learning_rate','mean_test_score']]\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이를 차트로 그려봅시다.\n",
    "plt.figure(figsize = (8,6))\n",
    "sns.lineplot(x = 'param_learning_rate', y = 'mean_test_score', data = temp, hue = 'param_n_estimators')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 복습문제\n",
    "* 카시트 데이터를 이용하여 랜덤포레스트 모델을 생성해 봅시다.\n",
    "    * 카시트 판매량 예측 : 회귀\n",
    "    * 기본 전처리\n",
    "    * 알고리즘 : **XGBRegressor** (회귀 모델)\n",
    "    * 모델 튜닝 : Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'https://raw.githubusercontent.com/DA4BAM/dataset/master/Carseats.csv'\n",
    "\n",
    "data = pd.read_csv(path)  # csv 파일을 불러올때, 지정한 칼럼의 데이터만 가져오기\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| 변수명 | 설명 | 구분 |\n",
    "|----|----|----|\n",
    "| Sales | 각 지역 판매량(단위 : 1000개) | Target |\n",
    "| CompPrice | 지역별 경쟁사 판매가격(달러) | feature |\n",
    "| Income | 가구당 평균 소득액(1000달러) | feature |\n",
    "| Advertising | 각 지역, 회사의 광고 예산(1000달러) | feature |\n",
    "| Population | 지역 인구수(단위 : 1000명) | feature |\n",
    "| Price | 자사 지역별 판매가격(달러) | feature |\n",
    "| ShelveLoc | 진열상태(범주 : Bad, Medium, Good) | feature |\n",
    "| Age | 지역 인구의 평균 연령 | feature |\n",
    "| Education | 교육수준(범주 : 10~18) | feature |\n",
    "| Urban | 매장이 도심에 있는지 여부(범주 : Yes, No) | feature |\n",
    "| US | 매장이 미국에 있는지 여부(범주 : Yes, No) | feature |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 데이터분할1 : x, y 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Sales'\n",
    "x = data.drop(target, axis=1)\n",
    "y = data.loc[:, target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 가변수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['ShelveLoc', 'US','Urban']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫번째 가변수 제거\n",
    "x = pd.get_dummies(x, columns=cat_cols, drop_first=True)\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) 데이터분할2 : train : validation 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size = .3, random_state = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) 모델링 : 튜닝\n",
    "* 성능 튜닝을 수행해 봅시다.\n",
    "* 하이퍼파라미터 범위\n",
    "    * cv = 3\n",
    "    * grid 파라미터\n",
    "        * max_depth : 3 ~ 8 사이에서 3개 선택\n",
    "        * n_estimators : 5 ~ 100 사이에서 5개 선택\n",
    "        * learning_rate :0.01 ~ 0.2 사이에서 3개 선택\n",
    "* 튜닝 후 검증셋으로 예측하고, RMSE, MAE, MAPE로 평가해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 1. 파라미터 그리드 생성\n",
    "# max_depth: 3~8 사이 3개 [3, 5, 8]\n",
    "# n_estimators: 5~100 사이 5개 [5, 25, 50, 75, 100]\n",
    "# learning_rate: 0.01~0.2 사이 3개 [0.01, 0.1, 0.2]\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 8],\n",
    "    'n_estimators': [5, 25, 50, 75, 100],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# 2. 모델 선언 (회귀 모델)\n",
    "model = XGBRegressor(objective='reg:squarederror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Grid Search 모델 선언 및 학습 (cv=3)\n",
    "model_gs = GridSearchCV(model, param_grid, cv=3)\n",
    "model_gs.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 최적 파라미터 및 점수 확인\n",
    "print(\"Best Parameters:\", model_gs.best_params_)\n",
    "print(\"Best Score:\", model_gs.best_score_)\n",
    "\n",
    "# 5. 예측\n",
    "pred = model_gs.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# 6. 평가 (RMSE, MAE, MAPE)\n",
    "print('RMSE :', mean_squared_error(y_val, pred, squared = True))\n",
    "print('MAE  :', mean_absolute_error(y_val, pred))\n",
    "print('MAPE :', mean_absolute_percentage_error(y_val, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
