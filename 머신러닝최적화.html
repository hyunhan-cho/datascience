<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>[실습 교안] 머신러닝 성능 최적화 (Hyperparameter Tuning)</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 900px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f9f9f9;
        }
        h1 {
            color: #2c3e50;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
        }
        h2 {
            color: #2980b9;
            margin-top: 40px;
            border-bottom: 1px solid #ddd;
            padding-bottom: 5px;
        }
        h3 {
            color: #16a085;
            margin-top: 30px;
        }
        h4 {
            color: #d35400;
            margin-top: 20px;
        }
        p {
            margin-bottom: 15px;
        }
        code {
            background-color: #e8e8e8;
            padding: 2px 4px;
            border-radius: 4px;
            font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
            color: #c7254e;
        }
        pre {
            background-color: #282c34;
            color: #abb2bf;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
            line-height: 1.5;
        }
        pre code {
            background-color: transparent;
            color: inherit;
            padding: 0;
            color: #abb2bf;
        }
        ul, ol {
            margin-bottom: 15px;
            padding-left: 20px;
        }
        li {
            margin-bottom: 5px;
        }
        .container {
            background-color: white;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .comment {
            color: #7f8c8d;
        }
    </style>
</head>
<body>

<div class="container">
    <h1>[실습 교안] 머신러닝 성능 최적화 (Hyperparameter Tuning)</h1>

    <p>본 교안은 머신러닝 모델의 성능을 끌어올리기 위한 <strong>Hyperparameter Tuning</strong> 과정을 담고 있습니다.<br>
    데이터 준비부터 Random Search, Grid Search, 그리고 시각화까지 단계별로 진행됩니다.<br>
    코드를 직접 입력하며 흐름을 익혀보세요.</p>

    <hr>

    <h2>1. 데이터 준비</h2>

    <h3>(1) 라이브러리 불러오기</h3>
    <p>데이터 처리를 위한 판다스, 수치 계산을 위한 넘파이, 시각화를 위한 맷플롯립/시본, 그리고 사이킷런의 필수 모듈들을 불러옵니다.</p>

    <pre><code>import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import *</code></pre>

    <h3>(2) 데이터 업로드</h3>
    <p>실습에 사용할 이동통신 고객 이탈(CHURN) 데이터를 불러옵니다. 불필요한 컬럼(<code>id</code> 등)은 제거합니다.</p>

    <pre><code><span class="comment"># mobile data 로딩</span>
path = "https://raw.githubusercontent.com/DA4BAM/dataset/master/mobile_cust_churn.csv"
data = pd.read_csv(path)

<span class="comment"># 분석에 불필요한 변수 제거</span>
data.drop(['id', 'REPORTED_USAGE_LEVEL','OVER_15MINS_CALLS_PER_MONTH'], axis = 1, inplace = True)

<span class="comment"># 데이터 상위 5행 확인</span>
data.head()</code></pre>

    <h3>(3) 데이터 전처리</h3>
    <p><strong>데이터 분할 및 가변수화, 스케일링</strong></p>
    <ol>
        <li><strong>x, y 분리</strong>: Target 변수('CHURN')와 Feature 변수를 분리합니다.</li>
        <li><strong>가변수화(One-Hot Encoding)</strong>: 범주형 변수를 숫자형으로 변환합니다 (<code>drop_first=True</code> 옵션 사용).</li>
        <li><strong>데이터 분할</strong>: 학습용(train)과 검증용(val) 데이터로 6:4 비율로 나눕니다.</li>
        <li><strong>스케일링(MinMaxScaler)</strong>: KNN 알고리즘은 거리 기반이므로 변수들의 단위를 맞추는 정규화가 필수입니다.</li>
    </ol>

    <pre><code><span class="comment"># 데이터분할1 : x, y 나누기</span>
target = 'CHURN'
x = data.drop(target, axis=1)
y = data.loc[:, target]

<span class="comment"># 가변수화 (범주형 변수 처리)</span>
dumm_cols = ['REPORTED_SATISFACTION','CONSIDERING_CHANGE_OF_PLAN']
x = pd.get_dummies(x, columns = dumm_cols, drop_first = True)

<span class="comment"># 데이터 분할2 : 학습용/검증용 나누기</span>
x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=.4, random_state = 20)

<span class="comment"># 스케일링 (KNN을 위해 필수)</span>
scaler = MinMaxScaler()
x_train_s = scaler.fit_transform(x_train)
x_val_s = scaler.transform(x_val)</code></pre>

    <hr>

    <h2>2. 모델링: Hyperparameter Tuning</h2>
    <p>모델의 성능을 최적화하기 위해 하이퍼파라미터를 조정합니다.</p>

    <h3>(1) Random Search</h3>
    <p><strong>Random Search</strong>는 파라미터의 범위를 지정하고, 그 범위 내에서 무작위로 값을 선택하여 시도해보는 방식입니다. 모든 경우의 수를 다 해보지 않으므로 상대적으로 빠릅니다.</p>

    <p><strong>작업 순서</strong></p>
    <ol>
        <li>파라미터 범위 지정 (Dictionary 형태)</li>
        <li><code>RandomizedSearchCV</code> 함수 불러오기</li>
        <li>기본 모델 선언 (KNN)</li>
        <li>Random Search 모델 선언 및 설정</li>
        <li>학습 (<code>fit</code>)</li>
        <li>예측 및 평가</li>
    </ol>

    <h4>1) 파라미터 범위 지정</h4>
    <p>KNN 모델에서 튜닝할 <code>n_neighbors</code>(이웃 수)와 <code>metric</code>(거리 계산 방식)의 범위를 지정합니다.</p>

    <pre><code><span class="comment"># 1) random하게 찾을 범위를 지정</span>
<span class="comment"># 지정하지 않는 파라미터는 default 값으로 지정됨.</span>
<span class="comment"># 파라미터를 dictionary 형태로 선언</span>
rand_param = { 
    'n_neighbors' : [3,5,7,9,11,13,15,17,19],  <span class="comment"># 이웃의 수 (홀수 권장)</span>
    'metric' : ['euclidean', 'manhattan']      <span class="comment"># 거리 계산 방식</span>
}

rand_param</code></pre>

    <h4>2) 함수 불러오기 및 모델 선언</h4>

    <pre><code><span class="comment"># 2) 함수 불러오기</span>
from sklearn.neighbors import KNeighborsClassifier

<span class="comment"># Random Search를 수행해 줄 함수!</span>
from sklearn.model_selection import RandomizedSearchCV</code></pre>

    <pre><code><span class="comment"># 3) 모델선언</span>
<span class="comment"># 기본모델</span>
knn_model = KNeighborsClassifier()

<span class="comment"># Random Search 설정</span>
rand_model = RandomizedSearchCV(knn_model,      <span class="comment"># 기본 모델</span>
                          rand_param,           <span class="comment"># hyperparameter 범위 지정</span>
                          cv=5,                 <span class="comment"># k-fold Cross Validation (5분할)</span>
                          scoring='accuracy',   <span class="comment"># 평가 기준 (정확도)</span>
                          n_iter=5              <span class="comment"># Random하게 시도할 횟수 (5회)</span>
                          )</code></pre>

    <h4>3) 학습 및 결과 확인</h4>
    <p>학습은 기본 모델이 아닌, <code>rand_model</code>을 사용하여 수행합니다.</p>

    <pre><code><span class="comment"># 4) 학습 : knn_model이 아니라 rand_model</span>
rand_model.fit(x_train_s, y_train)</code></pre>

    <p>학습이 완료되면, 시도했던 파라미터 조합들과 그 결과를 확인할 수 있습니다.</p>

    <pre><code><span class="comment"># 시행에 대한 상세 정보 확인</span>
rand_model.cv_results_</code></pre>

    <p>가장 성능이 좋았던 파라미터와 그때의 점수를 확인합니다.</p>

    <pre><code><span class="comment"># 최적의 파라미터 확인</span>
rand_model.best_params_</code></pre>

    <pre><code><span class="comment"># 최적의 성능 (교차검증 평균 정확도)</span>
rand_model.best_score_</code></pre>

    <h4>4) 예측 및 평가</h4>
    <p>최적의 파라미터로 학습된 모델을 사용하여 검증 데이터(<code>x_val_s</code>)를 예측하고 평가합니다.</p>

    <pre><code><span class="comment"># 5) 예측 및 평가</span>
pred = rand_model.predict(x_val_s)

from sklearn.metrics import confusion_matrix, classification_report, accuracy_score

print(confusion_matrix(y_val, pred))
print(classification_report(y_val, pred, digits = 4))</code></pre>

    <hr>

    <h3>(2) Grid Search</h3>
    <p><strong>Grid Search</strong>는 지정한 파라미터 범위 내의 <strong>모든 경우의 수</strong>를 다 시도해보는 방식입니다. 가장 확실하게 최적의 값을 찾을 수 있지만, 시간이 오래 걸릴 수 있습니다.</p>

    <h4>1) 파라미터 범위 지정 및 함수 불러오기</h4>
    <p>범위를 조금 더 넓게 잡아보겠습니다. (<code>n_neighbors</code>를 2부터 69까지 3단위로)</p>

    <pre><code><span class="comment"># 1) 파라미터를 dictionary 형태로 선언</span>
grid_param = {
    'n_neighbors' : list(range(2, 70, 3)),      <span class="comment"># 2, 5, 8 ... 68</span>
    'metric' : ['euclidean', 'manhattan']
}
grid_param</code></pre>

    <pre><code><span class="comment"># 2) 함수 불러오기</span>
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV  <span class="comment"># 이번엔 GridSearchCV</span></code></pre>

    <h4>2) 모델 선언 및 학습</h4>
    <p><code>n_iter</code> 옵션이 없습니다. (모든 경우를 다 하므로 횟수 지정 불필요)</p>

    <pre><code><span class="comment"># 3) 모델 선언</span>
knn = KNeighborsClassifier()

knn_gs = GridSearchCV(knn,
                     grid_param,
                     cv = 3    <span class="comment"># k-fold cross validation (3분할)</span>
                     ) <span class="comment"># scoring을 생략하면, 기본값으로 분류는 accuracy</span></code></pre>

    <pre><code><span class="comment"># 4) 학습</span>
<span class="comment"># 주의: 경우의 수가 많으면 시간이 오래 걸릴 수 있습니다.</span>
knn_gs.fit(x_train_s, y_train)</code></pre>

    <h4>3) 결과 확인</h4>

    <pre><code><span class="comment"># 최적의 파라미터를 찾아준다.</span>
knn_gs.best_params_</code></pre>

    <pre><code><span class="comment"># 최적의 성능 점수</span>
knn_gs.best_score_</code></pre>

    <h4>4) 예측 및 평가</h4>

    <pre><code><span class="comment"># 5) 예측 및 평가</span>
pred = knn_gs.predict(x_val_s)
print(accuracy_score(y_val, pred))</code></pre>

    <pre><code>from sklearn.metrics import confusion_matrix
print(confusion_matrix(y_val, pred))</code></pre>

    <pre><code>print(classification_report(y_val, pred))</code></pre>

    <h4>5) 튜닝 결과 시각화</h4>
    <p>Grid Search의 모든 결과를 데이터프레임으로 만들어 성능 변화를 시각적으로 확인해봅니다.</p>

    <pre><code><span class="comment"># 튜닝 결과를 데이터프레임으로 저장</span>
knn_gs.cv_results_
result = pd.DataFrame(knn_gs.cv_results_)
result.head()</code></pre>

    <pre><code><span class="comment"># 이 중에서 필요한 컬럼(파라미터와 평균 점수)만 별도로 저장합니다.</span>
temp = result.loc[:, ['param_metric', 'param_n_neighbors', 'mean_test_score']]
temp.head()</code></pre>

    <pre><code><span class="comment"># 이를 차트로 그려봅니다.</span>
<span class="comment"># x축: 이웃 수, y축: 점수, 색상: 거리 계산 방식</span>
sns.lineplot(x = 'param_n_neighbors', y = 'mean_test_score', data = temp, hue = 'param_metric')
plt.grid()
plt.show()</code></pre>

    <hr>

    <h3>(3) 실습 : Grid Search (Decision Tree)</h3>
    <p>이번에는 <strong>Decision Tree(의사결정나무)</strong> 모델을 사용하여 Grid Search를 직접 수행해봅니다.<br>
    <em>(노트북의 비어있는 부분을 채운 코드입니다.)</em></p>

    <ul>
        <li><strong>사용할 알고리즘</strong>: Decision Tree</li>
        <li><strong>튜닝 방식</strong>: Grid Search</li>
        <li><strong>파라미터 범위</strong>:
            <ul>
                <li><code>max_depth</code>: 1 ~ 15</li>
                <li><code>min_samples_leaf</code>: 10, 30, 50</li>
            </ul>
        </li>
    </ul>

    <h4>1) 파라미터 선언</h4>

    <pre><code><span class="comment"># 1) 파라미터를 dictionary 형태로 선언</span>
<span class="comment"># max_depth: 트리의 최대 깊이 (1부터 15까지)</span>
<span class="comment"># min_samples_leaf: 리프 노드가 되기 위한 최소 샘플 수</span>
params = {
    'max_depth': range(1, 16),
    'min_samples_leaf': [10, 30, 50]
}</code></pre>

    <h4>2) 함수 불러오기</h4>

    <pre><code><span class="comment"># 2) 함수 불러오기</span>
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV</code></pre>

    <h4>3) 모델 선언</h4>
    <p>Decision Tree 모델을 기본으로 하고, Grid Search 모델을 설정합니다.</p>

    <pre><code><span class="comment"># 3) 모델 선언</span>
dt_model = DecisionTreeClassifier()

<span class="comment"># Grid Search 설정</span>
<span class="comment"># cv=5 (5-fold 교차 검증)</span>
dt_gs = GridSearchCV(dt_model, params, cv=5, scoring='accuracy')</code></pre>

    <h4>4) 학습</h4>
    <p>트리 모델은 스케일링이 필요 없으므로 <code>x_train</code>(원본)을 사용해도 되지만, 편의상 앞서 준비한 데이터를 사용해도 무방합니다. 여기서는 <code>x_train</code>을 사용합니다.</p>

    <pre><code><span class="comment"># 4) 학습</span>
dt_gs.fit(x_train, y_train)</code></pre>

    <h4>5) 결과 확인 (Best Parameter & Score)</h4>

    <pre><code><span class="comment"># 5) 선택된 best parameter는?</span>
print("Best Parameters:", dt_gs.best_params_)

<span class="comment"># 6) best parameter에서의 cv 성능은?</span>
print("Best Score:", dt_gs.best_score_)</code></pre>

    <h4>6) 예측 및 평가</h4>
    <p>최종적으로 검증 데이터(<code>x_val</code>)를 이용해 성능을 평가합니다.</p>

    <pre><code><span class="comment"># 7) 예측 및 평가</span>
pred_dt = dt_gs.predict(x_val)

print(confusion_matrix(y_val, pred_dt))
print(classification_report(y_val, pred_dt))</code></pre>

    <hr>
    <p><strong>수고하셨습니다!</strong><br>
    이 과정을 통해 모델의 최적 파라미터를 찾는 방법(Random Search, Grid Search)을 익혔습니다.<br>
    데이터와 모델에 따라 최적의 파라미터는 달라지므로, 다양한 시도를 해보는 것이 중요합니다.</p>
</div>

</body>
</html>