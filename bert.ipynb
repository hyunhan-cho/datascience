{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "5b0a186d",
            "metadata": {},
            "source": [
                "# BERT Fine-Tuning Lab\n",
                "\n",
                "이 노트북은 **IMDB 영화 리뷰 데이터셋**을 사용하여 긍정/부정을 분류하는 모델을 만드는 과정을 담고 있습니다.\n",
                "사전 학습된 `distilbert-base-uncased` 모델을 가져와 파인튜닝(Fine-tuning)을 진행합니다."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "26b37c67",
            "metadata": {},
            "source": [
                "## 1. 라이브러리 설치\n",
                "\n",
                "Hugging Face의 `transformers`와 `datasets` 라이브러리를 설치합니다. \n",
                "이전 버전 호환성을 위해 `datasets`와 `fsspec` 버전을 특정합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "41e4e352",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Collecting datasets<=2.18.0\n",
                        "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
                        "Collecting fsspec<=2023.6.0\n",
                        "  Downloading fsspec-2023.6.0-py3-none-any.whl.metadata (6.7 kB)\n",
                        "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets<=2.18.0) (3.20.2)\n",
                        "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets<=2.18.0) (2.0.2)\n",
                        "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets<=2.18.0) (18.1.0)\n",
                        "Collecting pyarrow-hotfix (from datasets<=2.18.0)\n",
                        "  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
                        "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets<=2.18.0) (0.3.8)\n",
                        "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets<=2.18.0) (2.2.2)\n",
                        "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from datasets<=2.18.0) (2.32.4)\n",
                        "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from datasets<=2.18.0) (4.67.1)\n",
                        "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets<=2.18.0) (3.6.0)\n",
                        "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from datasets<=2.18.0) (0.70.16)\n",
                        "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from datasets<=2.18.0) (3.13.3)\n",
                        "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.12/dist-packages (from datasets<=2.18.0) (0.36.0)\n",
                        "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets<=2.18.0) (25.0)\n",
                        "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets<=2.18.0) (6.0.3)\n",
                        "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<=2.18.0) (2.6.1)\n",
                        "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<=2.18.0) (1.4.0)\n",
                        "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<=2.18.0) (25.4.0)\n",
                        "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<=2.18.0) (1.8.0)\n",
                        "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<=2.18.0) (6.7.0)\n",
                        "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<=2.18.0) (0.4.1)\n",
                        "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->datasets<=2.18.0) (1.22.0)\n",
                        "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.4->datasets<=2.18.0) (4.15.0)\n",
                        "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.4->datasets<=2.18.0) (1.2.0)\n",
                        "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets<=2.18.0) (3.4.4)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets<=2.18.0) (3.11)\n",
                        "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets<=2.18.0) (2.5.0)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->datasets<=2.18.0) (2026.1.4)\n",
                        "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<=2.18.0) (2.9.0.post0)\n",
                        "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<=2.18.0) (2025.2)\n",
                        "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets<=2.18.0) (2025.3)\n",
                        "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets<=2.18.0) (1.17.0)\n",
                        "Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
                        "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
                        "\u001b[?25hDownloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\n",
                        "Installing collected packages: pyarrow-hotfix, fsspec, datasets\n",
                        "  Attempting uninstall: fsspec\n",
                        "    Found existing installation: fsspec 2025.3.0\n",
                        "    Uninstalling fsspec-2025.3.0:\n",
                        "      Successfully uninstalled fsspec-2025.3.0\n",
                        "  Attempting uninstall: datasets\n",
                        "    Found existing installation: datasets 4.0.0\n",
                        "    Uninstalling datasets-4.0.0:\n",
                        "      Successfully uninstalled datasets-4.0.0\n",
                        "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
                        "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2023.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
                        "\u001b[0mSuccessfully installed datasets-2.18.0 fsspec-2023.6.0 pyarrow-hotfix-0.7\n"
                    ]
                }
            ],
            "source": [
                "# 세션 다시 시작 필요 (코랩 환경일 경우 설치 후 런타임 재시작 권장)\n",
                "!pip install -q transformers datasets\n",
                "!pip install -U \"datasets<=2.18.0\" \"fsspec<=2023.6.0\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ef7048fd",
            "metadata": {},
            "source": [
                "## 2. 데이터 로드 및 분할\n",
                "\n",
                "IMDB 영화 리뷰 데이터셋을 불러옵니다. 빠른 실습을 위해 **50개의 샘플**만 사용합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "c63682ba",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
                        "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
                        "You are not authenticated with the Hugging Face Hub in this notebook.\n",
                        "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "0ba060763ad34befab7bd3d36ac5de48",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading readme: 0.00B [00:00, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "bb1eadef4aef425d9d62d162de5d08b6",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading data:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "9be15abfb20c490c8cf0b8e85c0e8aab",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading data:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "9d5ed25adcb34ce1aa2822b7d511f226",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading data:   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "967340530f1f43bb9d5dcaaa225d8bb6",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "795541e870d34621990d45a1cb7a4f87",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "8cb42d9b028e427ea897e3fe990ea5a0",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "데이터셋 구조: DatasetDict({\n",
                        "    train: Dataset({\n",
                        "        features: ['text', 'label'],\n",
                        "        num_rows: 40\n",
                        "    })\n",
                        "    test: Dataset({\n",
                        "        features: ['text', 'label'],\n",
                        "        num_rows: 10\n",
                        "    })\n",
                        "})\n"
                    ]
                }
            ],
            "source": [
                "from datasets import load_dataset\n",
                "\n",
                "# 1. 데이터 로드\n",
                "# IMDB 영화 리뷰 데이터셋 중 50개 샘플만 가져와서 학습용/평가용으로 8:2 비율로 나눕니다\n",
                "dataset = load_dataset(\"imdb\", split=\"train[:50]\").train_test_split(test_size=0.2)\n",
                "\n",
                "# 데이터 확인\n",
                "print(\"데이터셋 구조:\", dataset)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "b07b4324",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        " 리뷰 내용:\n",
                        "This movie sucked. It really was a waste of my life. The acting was atrocious, the plot completely implausible. Long, long story short, these people get \"terrorized\" by this pathetic \"crazed killer\", but completely fail to fight back in any manner. And this is after they take a raft on a camping trip, with no gear, and show up at a campsite that is already assembled and completely stocked with food and clothes and the daughters headphones. Additionally, after their boat goes missing, they panic that they're stuck in the woods, but then the daughters boyfriend just shows up and they apparently never consider that they could just hike out of the woods like he did to get to them. Like I said, this movie sucks. A complete joke. Don't let your girlfriend talk you into watching it.\n",
                        "\n",
                        " 라벨 (0=부정, 1=긍정): 0\n"
                    ]
                }
            ],
            "source": [
                "# 샘플 데이터 확인 (인덱스 7)\n",
                "sample = dataset[\"train\"][7]\n",
                "print(f\" 리뷰 내용:\\n{sample['text']}\\n\")\n",
                "print(f\" 라벨 (0=부정, 1=긍정): {sample['label']}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9ae16966",
            "metadata": {},
            "source": [
                "## 3. 모델 및 토크나이저 준비\n",
                "\n",
                "`distilbert-base-uncased` 모델과 토크나이저를 불러옵니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "f0215385",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "2045015611494b25a89e727029d32dee",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "2039174d41484fd3bad96a472e670305",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "35e62e162b794c46aca7bc1a3995bc12",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "75887790c7534b6b9150619753452d11",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c82d6ad02c64441ca24ed174e59232b8",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
                        "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
                    ]
                }
            ],
            "source": [
                "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
                "\n",
                "# 2. 모델 및 토크나이저 준비\n",
                "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
                "# uncased: 대소문자 구분 없이 모두 소문자로 처리한다는 의미\n",
                "\n",
                "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\")\n",
                "# SequenceClassification: 문장 분류를 위한 헤드(Head)가 달린 모델을 불러옴"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "53ae3e71",
            "metadata": {},
            "source": [
                "## 4. 데이터 전처리 (토큰화)\n",
                "\n",
                "문장을 모델이 이해할 수 있는 숫자(토큰 ID)로 변환합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "29c69f5a",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "9e075c3facf44587b9795dc290963f94",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "baa929cc7595466cabaeeedabac6fa0d",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# 3. 데이터 전처리 (텍스트를 숫자 토큰으로 변환)\n",
                "def tokenize(batch):\n",
                "    return tokenizer(batch[\"text\"], truncation=True, padding=True)\n",
                "\n",
                "dataset = dataset.map(tokenize, batched=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "56a1269f",
            "metadata": {},
            "source": [
                "## 5. 훈련 설정 (Trainer)\n",
                "\n",
                "`Trainer`와 `TrainingArguments`를 설정하여 학습을 준비합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "05ef7e7c",
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import TrainingArguments, Trainer\n",
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "# 정확도 계산 함수: 모델의 예측값과 실제 정답을 비교하여 정확도를 계산\n",
                "def compute_metrics(eval_pred):\n",
                "    logits, labels = eval_pred\n",
                "    predictions = logits.argmax(axis=-1) # 확률이 가장 높은 클래스 선택\n",
                "    acc = accuracy_score(labels, predictions)\n",
                "    return {\"accuracy\": acc}\n",
                "\n",
                "# 훈련 파라미터 설정\n",
                "args = TrainingArguments(\n",
                "    output_dir=\"test\",              # 모델 체크포인트 저장 경로\n",
                "    per_device_train_batch_size=8,  # 배치 크기 (한 번에 학습할 데이터 수)\n",
                "    num_train_epochs=15,            # 학습 반복 횟수 (전체 데이터를 15번 봄)\n",
                "    report_to=\"none\",               # 외부 로깅 비활성화\n",
                "    logging_steps=1                 # 매 스텝마다 로그 출력\n",
                ")\n",
                "\n",
                "# Trainer 객체 생성\n",
                "trainer = Trainer(\n",
                "    model=model,                    # 학습시킬 모델\n",
                "    args=args,                      # 위에서 정의한 설정값\n",
                "    train_dataset=dataset[\"train\"], # 학습 데이터 (40개)\n",
                "    eval_dataset=dataset[\"test\"],   # 평가 데이터 (10개)\n",
                "    compute_metrics=compute_metrics # 평가 방식 (정확도)\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bc1b6e03",
            "metadata": {},
            "source": [
                "## 6. 파인튜닝 실행 및 평가\n",
                "\n",
                "모델 학습을 시작하고, 테스트 데이터로 성능을 평가합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "6f9647b5",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "\n",
                            "    <div>\n",
                            "      \n",
                            "      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                            "      [75/75 00:32, Epoch 15/15]\n",
                            "    </div>\n",
                            "    <table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            " <tr style=\"text-align: left;\">\n",
                            "      <th>Step</th>\n",
                            "      <th>Training Loss</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <td>1</td>\n",
                            "      <td>0.610400</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>2</td>\n",
                            "      <td>0.459200</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>3</td>\n",
                            "      <td>0.330100</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>4</td>\n",
                            "      <td>0.210800</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>5</td>\n",
                            "      <td>0.153200</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>6</td>\n",
                            "      <td>0.128900</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>7</td>\n",
                            "      <td>0.076600</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>8</td>\n",
                            "      <td>0.048500</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>9</td>\n",
                            "      <td>0.031600</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>10</td>\n",
                            "      <td>0.032800</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>11</td>\n",
                            "      <td>0.025300</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>12</td>\n",
                            "      <td>0.015100</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>13</td>\n",
                            "      <td>0.012800</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>14</td>\n",
                            "      <td>0.012400</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>15</td>\n",
                            "      <td>0.009900</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>16</td>\n",
                            "      <td>0.008000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>17</td>\n",
                            "      <td>0.008000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>18</td>\n",
                            "      <td>0.006900</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>19</td>\n",
                            "      <td>0.005800</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>20</td>\n",
                            "      <td>0.004300</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>21</td>\n",
                            "      <td>0.004100</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>22</td>\n",
                            "      <td>0.005000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>23</td>\n",
                            "      <td>0.003800</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>24</td>\n",
                            "      <td>0.003300</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>25</td>\n",
                            "      <td>0.003300</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>26</td>\n",
                            "      <td>0.003200</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>27</td>\n",
                            "      <td>0.002400</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>28</td>\n",
                            "      <td>0.002200</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>29</td>\n",
                            "      <td>0.002200</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>30</td>\n",
                            "      <td>0.002300</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>31</td>\n",
                            "      <td>0.001900</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>32</td>\n",
                            "      <td>0.001900</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>33</td>\n",
                            "      <td>0.001400</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>34</td>\n",
                            "      <td>0.001800</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>35</td>\n",
                            "      <td>0.001500</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>36</td>\n",
                            "      <td>0.001400</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>37</td>\n",
                            "      <td>0.001900</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>38</td>\n",
                            "      <td>0.001300</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>39</td>\n",
                            "      <td>0.001500</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>40</td>\n",
                            "      <td>0.001400</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>41</td>\n",
                            "      <td>0.001600</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>42</td>\n",
                            "      <td>0.001400</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>43</td>\n",
                            "      <td>0.001300</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>44</td>\n",
                            "      <td>0.001200</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>45</td>\n",
                            "      <td>0.001600</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>46</td>\n",
                            "      <td>0.001500</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>47</td>\n",
                            "      <td>0.001400</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>48</td>\n",
                            "      <td>0.001200</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>49</td>\n",
                            "      <td>0.001200</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>50</td>\n",
                            "      <td>0.001100</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>51</td>\n",
                            "      <td>0.001300</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>52</td>\n",
                            "      <td>0.001100</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>53</td>\n",
                            "      <td>0.001100</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>54</td>\n",
                            "      <td>0.001200</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>55</td>\n",
                            "      <td>0.001100</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>56</td>\n",
                            "      <td>0.001000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>57</td>\n",
                            "      <td>0.000900</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>58</td>\n",
                            "      <td>0.001100</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>59</td>\n",
                            "      <td>0.001000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>60</td>\n",
                            "      <td>0.001100</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>61</td>\n",
                            "      <td>0.001300</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>62</td>\n",
                            "      <td>0.001300</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>63</td>\n",
                            "      <td>0.000900</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>64</td>\n",
                            "      <td>0.001100</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>65</td>\n",
                            "      <td>0.001100</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>66</td>\n",
                            "      <td>0.001000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>67</td>\n",
                            "      <td>0.000900</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>68</td>\n",
                            "      <td>0.001100</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>69</td>\n",
                            "      <td>0.000900</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>70</td>\n",
                            "      <td>0.001200</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>71</td>\n",
                            "      <td>0.000900</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>72</td>\n",
                            "      <td>0.001100</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>73</td>\n",
                            "      <td>0.001000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>74</td>\n",
                            "      <td>0.001000</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <td>75</td>\n",
                            "      <td>0.001000</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table><p>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/plain": [
                            "TrainOutput(global_step=75, training_loss=0.03038031229361271, metrics={'train_runtime': 34.3887, 'train_samples_per_second': 17.448, 'train_steps_per_second': 2.181, 'total_flos': 79480439193600.0, 'train_loss': 0.03038031229361271, 'epoch': 15.0})"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# 5. 파인튜닝 실행 (모델 학습)\n",
                "trainer.train()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "ee19a077",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "\n",
                            "    <div>\n",
                            "      \n",
                            "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
                            "      [2/2 00:00]\n",
                            "    </div>\n",
                            "    "
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'eval_loss': 0.0008765311213210225, 'eval_accuracy': 1.0, 'eval_runtime': 0.2332, 'eval_samples_per_second': 42.877, 'eval_steps_per_second': 8.575, 'epoch': 15.0}\n"
                    ]
                }
            ],
            "source": [
                "# 6. 모델 평가\n",
                "results = trainer.evaluate()\n",
                "print(results)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "12550fb6",
            "metadata": {},
            "source": [
                "## 7. 실제 예측 수행 (Inference)\n",
                "\n",
                "학습된 모델을 사용하여 새로운 문장의 감정을 예측합니다."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "8d3db1aa",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "입력 문장: I would put this at the top of my list of films in the category of unwatchable trash!\n",
                        "예측 결과: 부정\n"
                    ]
                }
            ],
            "source": [
                "import torch\n",
                "\n",
                "# 6. 학습된 모델로 실제 예측 수행\n",
                "text = \"I would put this at the top of my list of films in the category of unwatchable trash!\"\n",
                "# \"이 영화를 내 '시청 불가 쓰레기' 카테고리 영화 리스트의 맨 위에 올리겠다!\" (혹평)\n",
                "\n",
                "# 1. 토큰화 및 장치 이동\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "model.to(device)\n",
                "\n",
                "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
                "\n",
                "# 2. 모델 예측\n",
                "with torch.no_grad():\n",
                "    output = model(**inputs)\n",
                "\n",
                "# 3. 결과 해석 (Logits -> Label)\n",
                "label = output.logits.argmax(-1).item()\n",
                "# output.logits는 [부정점수, 긍정점수] 형태입니다.\n",
                "# argmax(-1)은 둘 중 더 큰 점수의 위치(인덱스)를 찾습니다.\n",
                "\n",
                "print(f\"입력 문장: {text}\")\n",
                "print(\"예측 결과:\", \"긍정\" if label == 1 else \"부정\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
