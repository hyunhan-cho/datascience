<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>NLP 스터디</title>
    <style>
        body {
            font-family: 'Malgun Gothic', 'Noto Sans KR', sans-serif;
            margin: 0;
            padding: 0;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            line-height: 1.6;
            overflow-x: hidden;
            overflow-y: auto;
        }
        .header {
            text-align: center;
            padding: 60px 20px;
            color: white;
        }
        .header h1 {
            font-size: 3.2em;
            margin: 0;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }
        .header p {
            font-size: 1.1em;
            margin-top: 10px;
            opacity: 0.9;
        }
        .back-button {
            display: inline-block;
            margin-bottom: 20px;
            padding: 10px 20px;
            background: rgba(255,255,255,0.2);
            color: white;
            text-decoration: none;
            border-radius: 25px;
            transition: all 0.3s ease;
        }
        .back-button:hover {
            background: rgba(255,255,255,0.3);
            transform: translateY(-2px);
        }
        .main-content { max-width: 1200px; margin: 0 auto; padding: 0 20px 60px; }
        .study-grid { display: grid; grid-template-columns: repeat(auto-fill, minmax(320px, 1fr)); gap: 25px; padding: 20px 0; max-width: 100%; }
        .study-card { background: white; border-radius: 15px; overflow: hidden; box-shadow: 0 8px 25px rgba(0,0,0,0.1); transition: all 0.3s ease; }
        .study-card:hover { transform: translateY(-5px); box-shadow: 0 15px 35px rgba(0,0,0,0.2); }
        .study-link { display: block; text-decoration: none; color: inherit; }
        .study-card-header { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 25px; position: relative; }
        .study-number { font-size: 3em; font-weight: bold; opacity: 0.25; position: absolute; right: 20px; top: 10px; }
        .study-card-title { font-size: 1.7em; font-weight: 800; margin-bottom: 6px; }
        .study-card-subtitle { opacity: 0.92; font-size: 1.05em; }
        .study-card-body { padding: 22px 25px; }
        .study-card-description { color: #5b6470; margin-bottom: 14px; }
        .study-tags { display: flex; flex-wrap: wrap; gap: 8px; }
        .tag { background: #f8f9fa; color: #667eea; padding: 5px 12px; border-radius: 15px; font-size: 0.85em; font-weight: 600; }
        .footer { text-align: center; padding: 40px 20px; color: white; opacity: 0.85; }
        @media (max-width: 768px) {
            .header h1 { font-size: 2.4em; }
            .study-grid { grid-template-columns: 1fr; }
            .main-content { padding: 0 15px 40px; }
        }
        @media (max-width: 1024px) and (min-width: 769px) {
            .study-grid { grid-template-columns: repeat(2, 1fr); }
        }
        @media (min-width: 1025px) {
            .study-grid { grid-template-columns: repeat(3, 1fr); max-width: 1200px; margin: 0 auto; }
        }
        /* Embed section */
        .embed { background: white; border-radius: 15px; box-shadow: 0 8px 25px rgba(0,0,0,0.1); overflow: hidden; }
        .embed-header { background: #111827; color: #e5e7eb; padding: 14px 18px; display: flex; justify-content: space-between; align-items: center; }
        .embed-header a { color: #93c5fd; text-decoration: none; font-weight: 700; }
        .embed iframe { width: 100%; height: 680px; border: 0; display: block; }
        .hidden { display: none; }
    </style>
</head>
<body>
    <div class="header">
        <a href="index.html" class="back-button">← 메인으로 돌아가기</a>
        <h1>🧠 NLP Study</h1>
        <p>자연어 처리와 LLM 관련 핵심 주제와 실무 활용 사례를 모았습니다</p>
    </div>

    <div class="main-content">
        <div class="study-grid">
            <div class="study-card">
                <a href="환각.html" class="study-link">
                    <div class="study-card-header">
                        <div class="study-number">01</div>
                        <div class="study-card-title">LLM 환각(Hallucination)</div>
                        <div class="study-card-subtitle">저널리즘 맥락에서의 리스크와 저감 전략</div>
                    </div>
                    <div class="study-card-body">
                        <div class="study-card-description">
                            LLM 환각의 원인과 유형, 저널리즘 워크플로우에서의 리스크, 그리고 RAG/CoVe 등 저감 기법을 슬라이드로 정리했습니다.
                        </div>
                        <div class="study-tags">
                            <span class="tag">LLM</span>
                            <span class="tag">Hallucination</span>
                            <span class="tag">RAG</span>
                            <span class="tag">Evaluation</span>
                        </div>
                    </div>
                </a>
            </div>
            
            <div class="study-card">
                <a href="ai와지식.html" class="study-link">
                    <div class="study-card-header">
                        <div class="study-number">02</div>
                        <div class="study-card-title">지식: 인간과 AI</div>
                        <div class="study-card-subtitle">인식론의 여정과 AI 시대의 질문</div>
                    </div>
                    <div class="study-card-body">
                        <div class="study-card-description">
                            지식이란 무엇인가에 대한 철학적 여정과 AI 시대에 제기되는 새로운 질문들을 탐구합니다. 인간의 지식과 AI의 '지식' 사이의 본질적 차이를 다룹니다.
                        </div>
                        <div class="study-tags">
                            <span class="tag">Epistemology</span>
                            <span class="tag">Knowledge</span>
                            <span class="tag">AI Philosophy</span>
                            <span class="tag">Critical Thinking</span>
                        </div>
                    </div>
                </a>
            </div>
            
            <div class="study-card">
                <a href="딥러닝.html" class="study-link">
                    <div class="study-card-header">
                        <div class="study-number">03</div>
                        <div class="study-card-title">딥러닝과 트랜스포머</div>
                        <div class="study-card-subtitle">신경망부터 Transformer까지의 여정</div>
                    </div>
                    <div class="study-card-body">
                        <div class="study-card-description">
                            퍼셉트론부터 심층 신경망, 그리고 현대 AI의 핵심인 트랜스포머 아키텍처까지의 발전 과정을 학습합니다. 수식과 시각화로 이해하는 딥러닝의 핵심 개념들을 다룹니다.
                        </div>
                        <div class="study-tags">
                            <span class="tag">Deep Learning</span>
                            <span class="tag">Transformer</span>
                            <span class="tag">Neural Networks</span>
                            <span class="tag">Attention</span>
                        </div>
                    </div>
                </a>
            </div>
            
            <div class="study-card">
                <a href="skipgram.html" class="study-link">
                    <div class="study-card-header">
                        <div class="study-number">04</div>
                        <div class="study-card-title">Word2Vec과 Skip-gram</div>
                        <div class="study-card-subtitle">단어의 벡터화와 의미 표현</div>
                    </div>
                    <div class="study-card-body">
                        <div class="study-card-description">
                            분포 의미론부터 Word2Vec의 Skip-gram 모델까지, 단어를 벡터로 변환하는 핵심 기법을 학습합니다. 벡터 연산, 코사인 유사도, 그리고 신경망 기반 임베딩의 원리를 다룹니다.
                        </div>
                        <div class="study-tags">
                            <span class="tag">Word2Vec</span>
                            <span class="tag">Skip-gram</span>
                            <span class="tag">Embeddings</span>
                            <span class="tag">Vector Semantics</span>
                        </div>
                    </div>
                </a>
            </div>

            <div class="study-card">
                <a href="attention.html" class="study-link">
                    <div class="study-card-header">
                        <div class="study-number">05</div>
                        <div class="study-card-title">어텐션 메커니즘</div>
                        <div class="study-card-subtitle">Transformer의 핵심, 어텐션 심층 분석</div>
                    </div>
                    <div class="study-card-body">
                        <div class="study-card-description">
                            어텐션 메커니즘의 기본 원리부터 Query, Key, Value의 개념까지 단계별로 학습합니다. 텐서 연산, 내적, 가중합의 핵심 개념과 Softmax를 통한 가중치 정규화 과정을 시각화와 수식으로 이해할 수 있습니다.
                        </div>
                        <div class="study-tags">
                            <span class="tag">Attention</span>
                            <span class="tag">Transformer</span>
                            <span class="tag">Query-Key-Value</span>
                            <span class="tag">Softmax</span>
                            <span class="tag">Context Vector</span>
                        </div>
                    </div>
                </a>
            </div>

            <div class="study-card">
                <a href="selfattention.html" class="study-link">
                    <div class="study-card-header">
                        <div class="study-number">06</div>
                        <div class="study-card-title">Transformer 완전 분석</div>
                        <div class="study-card-subtitle">Attention Is All You Need</div>
                    </div>
                    <div class="study-card-body">
                        <div class="study-card-description">
                            2017년 Google이 발표한 혁신적인 Transformer 모델의 전체 구조를 상세히 분석합니다. 인코더-디코더 구조, Self-Attention, Multi-Head Attention, Positional Encoding 등 핵심 개념들을 체계적으로 학습할 수 있습니다.
                        </div>
                        <div class="study-tags">
                            <span class="tag">Transformer</span>
                            <span class="tag">Self-Attention</span>
                            <span class="tag">Multi-Head</span>
                            <span class="tag">Encoder-Decoder</span>
                            <span class="tag">Positional Encoding</span>
                        </div>
                    </div>
                </a>
            </div>

            <div class="study-card">
                <a href="kldeivergence.html" class="study-link">
                    <div class="study-card-header">
                        <div class="study-number">07</div>
                        <div class="study-card-title">KL Divergence</div>
                        <div class="study-card-subtitle">쿨백-라이블러 발산과 정보 이론</div>
                    </div>
                    <div class="study-card-body">
                        <div class="study-card-description">
                            두 확률분포 간의 차이를 측정하는 핵심 지표인 KL Divergence를 상세히 학습합니다. 정보 이론의 기초부터 VAE, 강화학습에서의 실제 활용까지, Mode-Covering과 Mode-Seeking의 차이를 시각화로 이해할 수 있습니다.
                        </div>
                        <div class="study-tags">
                            <span class="tag">KL Divergence</span>
                            <span class="tag">Information Theory</span>
                            <span class="tag">VAE</span>
                            <span class="tag">Cross-Entropy</span>
                            <span class="tag">Mode-Covering</span>
                        </div>
                    </div>
                </a>
            </div>

            <div class="study-card">
                <a href="masked.html" class="study-link">
                    <div class="study-card-header">
                        <div class="study-number">08</div>
                        <div class="study-card-title">Masked Language Model</div>
                        <div class="study-card-subtitle">BERT와 마스킹 기법의 이해</div>
                    </div>
                    <div class="study-card-body">
                        <div class="study-card-description">
                            BERT의 핵심인 Masked Language Model(MLM)의 작동 원리를 학습합니다. 양방향 문맥 이해, 마스킹 전략, 그리고 사전 훈련과 파인튜닝 과정을 통해 현대 NLP의 기초를 다집니다.
                        </div>
                        <div class="study-tags">
                            <span class="tag">BERT</span>
                            <span class="tag">Masked LM</span>
                            <span class="tag">Pre-training</span>
                            <span class="tag">Bidirectional</span>
                            <span class="tag">Fine-tuning</span>
                        </div>
                    </div>
                </a>
            </div>

            <div class="study-card">
                <a href="backpropagation.html" class="study-link">
                    <div class="study-card-header">
                        <div class="study-number">09</div>
                        <div class="study-card-title">역전파와 계산 그래프</div>
                        <div class="study-card-subtitle">Backpropagation & Computation Graphs</div>
                    </div>
                    <div class="study-card-body">
                        <div class="study-card-description">
                            신경망 학습의 핵심인 역전파 알고리즘을 계산 그래프로 시각화하여 학습합니다. 연쇄 법칙, 순전파/역전파 과정, 그리고 기울기 계산의 상세한 단계를 다룹니다.
                        </div>
                        <div class="study-tags">
                            <span class="tag">Backpropagation</span>
                            <span class="tag">Computation Graph</span>
                            <span class="tag">Chain Rule</span>
                            <span class="tag">Gradients</span>
                            <span class="tag">Neural Networks</span>
                        </div>
                    </div>
                </a>
            </div>
        </div>

        <!-- 동적 임베드 컨테이너 -->
        <section id="embed-container" class="embed hidden" aria-label="NLP 슬라이드 임베드 보기">
            <div class="embed-header">
                <strong id="embed-title">슬라이드 바로 보기</strong>
                <a id="embed-external" href="#" target="_blank" rel="noopener">새 창에서 보기 ↗</a>
            </div>
            <iframe id="embed-frame" src="" title="NLP Slides"></iframe>
        </section>
    </div>

    <div class="footer">
        <p>© 2025 NLP Study</p>
    </div>

    <script>
        // 카드 클릭 시 아래에 임베드 표시
        document.addEventListener('DOMContentLoaded', () => {
            const links = document.querySelectorAll('.study-card .study-link');
            const embed = document.getElementById('embed-container');
            const embedFrame = document.getElementById('embed-frame');
            const embedTitle = document.getElementById('embed-title');
            const embedExternal = document.getElementById('embed-external');

            links.forEach(link => {
                link.addEventListener('click', (e) => {
                    e.preventDefault();
                    const href = link.getAttribute('href');
                    const titleEl = link.querySelector('.study-card-title');
                    const titleText = titleEl ? titleEl.textContent.trim() : '슬라이드';

                    embedFrame.src = href;
                    embedTitle.textContent = `${titleText} · 슬라이드 바로 보기`;
                    embedExternal.href = href;
                    embed.classList.remove('hidden');
                    embed.scrollIntoView({ behavior: 'smooth', block: 'start' });
                });
            });
        });
    </script>
</body>
</html>
