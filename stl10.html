<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>STL10 다중 클래스 분류 프로젝트 분석</title>
    <!-- Tailwind CSS for Layout -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Prism.js for Syntax Highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet" />
    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@300;400;500;700&family=Fira+Code:wght@400;500&display=swap" rel="stylesheet">
    
    <style>
        body {
            font-family: 'Noto Sans KR', sans-serif;
            background-color: #f8f9fa;
            color: #333;
            line-height: 1.7;
        }
        
        .code-font {
            font-family: 'Fira Code', monospace;
        }

        /* Sidebar Navigation */
        .sidebar {
            position: fixed;
            top: 0;
            left: 0;
            width: 280px;
            height: 100vh;
            background: #ffffff;
            border-right: 1px solid #e5e7eb;
            overflow-y: auto;
            padding: 2rem 1.5rem;
            display: none; /* Mobile default */
            z-index: 50;
        }
        
        @media (min-width: 1024px) {
            .sidebar {
                display: block;
            }
            .main-content {
                margin-left: 280px;
            }
        }

        .nav-link {
            display: block;
            padding: 0.5rem 0;
            color: #6b7280;
            transition: all 0.2s;
            font-size: 0.9rem;
            border-left: 2px solid transparent;
            padding-left: 1rem;
        }

        .nav-link:hover, .nav-link.active {
            color: #3b82f6;
            border-left-color: #3b82f6;
            font-weight: 500;
        }

        /* Main Content Cards */
        .card {
            background: white;
            border-radius: 12px;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
            padding: 2rem;
            margin-bottom: 2rem;
            border: 1px solid #f0f0f0;
        }

        .section-title {
            font-size: 1.5rem;
            font-weight: 700;
            color: #111827;
            margin-bottom: 1rem;
            display: flex;
            align-items: center;
            gap: 0.5rem;
        }
        
        .section-title::before {
            content: '#';
            color: #3b82f6;
        }

        .explanation {
            background-color: #f0f9ff;
            border-left: 4px solid #3b82f6;
            padding: 1rem;
            border-radius: 4px;
            margin-bottom: 1.5rem;
            font-size: 0.95rem;
            color: #1e293b;
        }

        /* Code Block Styling */
        pre[class*="language-"] {
            border-radius: 8px;
            margin: 1rem 0;
            font-size: 0.9rem;
            box-shadow: inset 0 2px 4px rgba(0,0,0,0.3);
        }

        .output-block {
            background-color: #2d2d2d;
            color: #e6e6e6;
            padding: 1rem;
            border-radius: 8px;
            margin-top: -0.5rem;
            margin-bottom: 1.5rem;
            font-family: 'Fira Code', monospace;
            font-size: 0.85rem;
            white-space: pre-wrap;
            border-top: 1px solid #444;
        }

        .output-label {
            font-size: 0.75rem;
            text-transform: uppercase;
            color: #9ca3af;
            margin-bottom: 0.25rem;
            font-weight: bold;
        }

        /* Badge Styles */
        .badge {
            display: inline-block;
            padding: 0.25rem 0.5rem;
            border-radius: 9999px;
            font-size: 0.75rem;
            font-weight: 600;
            margin-right: 0.5rem;
        }
        .badge-torch { background-color: #ee4c2c; color: white; }
        .badge-data { background-color: #10b981; color: white; }
        .badge-model { background-color: #8b5cf6; color: white; }

    </style>
</head>
<body>

    <!-- Sidebar Navigation -->
    <nav class="sidebar">
        <div class="mb-8">
            <h1 class="text-2xl font-bold text-gray-800 tracking-tight">STL10 분류</h1>
            <p class="text-sm text-gray-500 mt-2">Deep CNN with PyTorch</p>
        </div>
        <div class="space-y-1">
            <a href="#setup" class="nav-link">1. 환경 설정 및 라이브러리</a>
            <a href="#hyperparams" class="nav-link">2. 하이퍼파라미터 설정</a>
            <a href="#transform" class="nav-link">3. 데이터 전처리 (Transforms)</a>
            <a href="#dataset" class="nav-link">4. 데이터셋 로드 및 분할</a>
            <a href="#visualize" class="nav-link">5. 데이터 확인 및 시각화</a>
            <a href="#model" class="nav-link">6. 모델 설계 (CNN_deep)</a>
            <a href="#training" class="nav-link">7. 학습 (Training Loop)</a>
            <a href="#history" class="nav-link">8. 학습 결과 및 그래프</a>
            <a href="#test" class="nav-link">9. 테스트 및 평가</a>
        </div>
        <div class="mt-8 pt-8 border-t border-gray-200">
            <p class="text-xs text-gray-400">Created via Gemini</p>
        </div>
    </nav>

    <!-- Main Content -->
    <main class="main-content p-6 lg:p-12">
        
        <!-- Header -->
        <header class="max-w-4xl mx-auto mb-12">
            <h1 class="text-4xl font-bold text-gray-900 mb-4">STL10 이미지 다중 클래스 분류</h1>
            <p class="text-lg text-gray-600">
                PyTorch를 활용하여 STL10 데이터셋을 학습하는 Deep CNN 모델 구현 프로젝트입니다.
                데이터 전처리부터 모델 설계, 학습, 그리고 결과 시각화까지의 전체 파이프라인을 상세하게 다룹니다.
            </p>
            <div class="mt-4 flex gap-2">
                <span class="badge badge-torch">PyTorch</span>
                <span class="badge badge-data">STL10 Dataset</span>
                <span class="badge badge-model">CNN</span>
            </div>
        </header>

        <div class="max-w-4xl mx-auto">
            
            <!-- Section 1: Setup -->
            <section id="setup" class="card">
                <h2 class="section-title">1. 환경 설정 및 라이브러리 임포트</h2>
                <div class="explanation">
                    <p>먼저 Google Drive를 마운트하고 필요한 라이브러리들을 불러옵니다. PyTorch, Torchvision 등 딥러닝 필수 라이브러리와 데이터 시각화를 위한 Matplotlib, 그리고 사용자 정의 모듈인 <code>multiclass_functions2</code>를 가져옵니다. GPU 사용 가능 여부도 확인합니다.</p>
                </div>
                <pre><code class="language-python">from google.colab import drive
drive.mount('/content/drive')
import sys
sys.path.append('/content/drive/MyDrive/Colab Notebooks/LEVEL 1/torch')
from multiclass_functions2 import * # my module import
import torch
from torch import nn, optim
from torchvision import datasets, transforms
from torch.utils.data import Dataset, DataLoader, random_split
import numpy as np
import matplotlib.pyplot as plt

# GPU 사용 가능 여부 확인
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
print(DEVICE)</code></pre>
                <div class="output-label">OUTPUT</div>
                <div class="output-block">Mounted at /content/drive
cuda</div>
            </section>

            <!-- Section 2: Hyperparameters -->
            <section id="hyperparams" class="card">
                <h2 class="section-title">2. 하이퍼파라미터 및 경로 설정</h2>
                <div class="explanation">
                    <p>학습에 필요한 주요 설정값들을 정의합니다. 배치 사이즈, 학습률(Learning Rate), 에폭(Epoch) 수 등을 설정하고, 모델과 학습 기록을 저장할 경로를 지정합니다.</p>
                </div>
                <pre><code class="language-python">BATCH_SIZE = 64
LR = 2e-3
LR_STEP = 3
LR_GAMMA = 0.9
LAMBDA = 1e-6
EPOCH = 15
criterion = nn.CrossEntropyLoss()
new_model_train = False
model_type = "CNN_deep"
dataset = "STL10"
save_model_path = f'/content/drive/MyDrive/Colab Notebooks/results/{model_type}_{dataset}.pt'
save_history_path = f'/content/drive/MyDrive/Colab Notebooks/results/{model_type}_history_{dataset}.pt'</code></pre>
            </section>

            <!-- Section 3: Transforms -->
            <section id="transform" class="card">
                <h2 class="section-title">3. 데이터 전처리 (Transforms) 정의</h2>
                <div class="explanation">
                    <p>학습 데이터의 다양성을 높이기 위해 <strong>Data Augmentation</strong>(데이터 증강)을 적용합니다. <code>RandomAffine</code>을 사용하여 이미지를 회전, 이동, 스케일링하여 모델의 일반화 성능을 높입니다. 테스트 데이터는 텐서 변환만 수행합니다.</p>
                </div>
                <pre><code class="language-python">transform_train = transforms.Compose([
    transforms.RandomAffine(degrees=(0,10), translate=(0.1,0.2), scale=(0.5,1.2)),
    transforms.ToTensor()])

transform_test = transforms.Compose([
    transforms.ToTensor()])</code></pre>
            </section>

            <!-- Section 4: Custom Dataset Wrapper -->
            <section id="dataset" class="card">
                <h2 class="section-title">4. Custom Dataset Wrapper & 로드</h2>
                <div class="explanation">
                    <p><code>random_split</code>을 사용하면 데이터셋이 <code>Subset</code> 객체가 되어 <code>transform</code> 속성을 직접 수정하기 어렵습니다. 이를 해결하기 위해 <code>SubsetWithTransform</code>이라는 커스텀 클래스를 정의하여 Train셋과 Validation셋에 서로 다른 전처리를 적용할 수 있도록 합니다.</p>
                </div>
                
                <h3 class="text-lg font-semibold mb-2">4-1. Custom Wrapper Class</h3>
                <pre><code class="language-python">class SubsetWithTransform(Dataset):
    def __init__(self, subset, transform=None):
        self.subset = subset
        self.transform = transform
        self.classes = subset.dataset.classes

    def __len__(self):
        return len(self.subset)

    def __getitem__(self, idx):
        x, y = self.subset[idx]
        if self.transform:
            x = self.transform(x)
        return x, y</code></pre>

                <h3 class="text-lg font-semibold mb-2 mt-6">4-2. 데이터셋 로드 및 분할</h3>
                <div class="explanation">
                    <p>STL10 데이터셋을 다운로드하고, Train 데이터를 8:2 비율로 Train/Validation 셋으로 나눕니다. 그 후 앞서 만든 Wrapper를 사용하여 각각의 Transform을 적용하고 DataLoader를 생성합니다.</p>
                </div>
                <pre><code class="language-python">train_DS = datasets.STL10(root = '/content/drive/MyDrive/Colab Notebooks/data', split="train", download=True)
NoT = int(0.8 * len(train_DS))
NoV = len(train_DS) - NoT
train_DS, val_DS = random_split(train_DS, [NoT, NoV])

# Wrapper를 사용하여 각각 다른 transform 적용
train_DS = SubsetWithTransform(train_DS, transform=transform_train) 
val_DS = SubsetWithTransform(val_DS, transform=transform_test) 
test_DS = datasets.STL10(root = '/content/drive/MyDrive/Colab Notebooks/data', split="test", download=True, transform=transform_test)

train_DL = DataLoader(train_DS, batch_size = BATCH_SIZE, shuffle = True)
val_DL = DataLoader(val_DS, batch_size = BATCH_SIZE, shuffle = True)
test_DL = DataLoader(test_DS, batch_size = BATCH_SIZE, shuffle = True)</code></pre>

                <h3 class="text-lg font-semibold mb-2 mt-6">4-3. 데이터 개수 확인</h3>
                <pre><code class="language-python">print(len(train_DS))
print(len(val_DS))
print(len(test_DS))</code></pre>
                <div class="output-label">OUTPUT</div>
                <div class="output-block">4000
1000
8000</div>
            </section>

            <!-- Section 5: Visualization -->
            <section id="visualize" class="card">
                <h2 class="section-title">5. 데이터 확인 및 시각화</h2>
                <div class="explanation">
                    <p>데이터가 올바르게 로드되었는지 확인하기 위해 각 DataLoader에서 배치를 하나씩 꺼내어 이미지와 라벨을 출력해봅니다. 이미지는 (C, H, W) 형태이므로 <code>permute(1, 2, 0)</code>을 통해 (H, W, C) 형태로 바꿔 시각화합니다.</p>
                </div>

                <h3 class="text-lg font-semibold mb-2">Train Set 확인</h3>
                <pre><code class="language-python">print(test_DS.classes)
x_batch, y_batch = next(iter(train_DL))
print(x_batch.shape)
plt.imshow(x_batch[0].permute(1,2,0))
print(test_DS.classes[y_batch[0]])</code></pre>
                <div class="output-label">OUTPUT</div>
                <div class="output-block">['airplane', 'bird', 'car', 'cat', 'deer', 'dog', 'horse', 'monkey', 'ship', 'truck']
torch.Size([64, 3, 96, 96])
deer</div>

                <h3 class="text-lg font-semibold mb-2 mt-6">Validation Set 확인</h3>
                <pre><code class="language-python">x_batch, y_batch = next(iter(val_DL))
print(x_batch.shape)
plt.imshow(x_batch[0].permute(1,2,0))
print(test_DS.classes[y_batch[0]])</code></pre>
                <div class="output-label">OUTPUT</div>
                <div class="output-block">torch.Size([64, 3, 96, 96])
cat</div>

                <h3 class="text-lg font-semibold mb-2 mt-6">Test Set 확인</h3>
                <pre><code class="language-python">x_batch, y_batch = next(iter(test_DL))
print(x_batch.shape)
plt.imshow(x_batch[0].permute(1,2,0))
print(test_DS.classes[y_batch[0]])</code></pre>
                <div class="output-label">OUTPUT</div>
                <div class="output-block">torch.Size([64, 3, 96, 96])
bird</div>
            </section>

            <!-- Section 6: Model Architecture -->
            <section id="model" class="card">
                <h2 class="section-title">6. 모델 설계 (CNN_deep)</h2>
                <div class="explanation">
                    <p>VGG 스타일의 깊은 CNN 모델을 정의합니다. 3개의 Convolutional Block으로 구성되어 있으며, 각 블록은 <code>Conv2d -> BatchNorm -> ReLU</code> 구조를 반복하고 마지막에 MaxPool로 크기를 줄입니다. 최종적으로 Fully Connected Layer를 통해 10개의 클래스로 분류합니다.</p>
                </div>
                <pre><code class="language-python">class CNN_deep(nn.Module):
    def __init__(self):
        super().__init__()
        # Block 1: 32 filters
        self.conv_block1 = nn.Sequential(nn.Conv2d(3,32,3,padding=1, bias=False),
                                         nn.BatchNorm2d(32),
                                         nn.ReLU(),
                                         nn.Conv2d(32,32,3,padding=1, bias=False),
                                         nn.BatchNorm2d(32),
                                         nn.ReLU())
        self.Maxpool1 = nn.MaxPool2d(2)

        # Block 2: 64 filters
        self.conv_block2 = nn.Sequential(nn.Conv2d(32,64,3,padding=1, bias=False),
                                         nn.BatchNorm2d(64),
                                         nn.ReLU(),
                                         nn.Conv2d(64,64,3,padding=1, bias=False),
                                         nn.BatchNorm2d(64),
                                         nn.ReLU(),
                                         nn.Conv2d(64,64,3,padding=1, bias=False),
                                         nn.BatchNorm2d(64),
                                         nn.ReLU())
        self.Maxpool2 = nn.MaxPool2d(2)

        # Block 3: 128 filters
        self.conv_block3 = nn.Sequential(nn.Conv2d(64,128,3,padding=1, bias=False),
                                         nn.BatchNorm2d(128),
                                         nn.ReLU(),
                                         nn.Conv2d(128,128,3,padding=1, bias=False),
                                         nn.BatchNorm2d(128),
                                         nn.ReLU(),
                                         nn.Conv2d(128,128,3,padding=1, bias=False),
                                         nn.BatchNorm2d(128),
                                         nn.ReLU())
        self.Maxpool3 = nn.MaxPool2d(2)

        # Classifier
        self.classifier = nn.Sequential(nn.Linear(128*12*12,512),
                                        nn.ReLU(),
                                        nn.Linear(512,10))

    def forward(self, x):
        x = self.conv_block1(x)
        x = self.Maxpool1(x)
        x = self.conv_block2(x)
        x = self.Maxpool2(x)
        x = self.conv_block3(x)
        x = self.Maxpool3(x)
        x = torch.flatten(x, start_dim=1)
        x = self.classifier(x)
        return x</code></pre>
                
                <h3 class="text-lg font-semibold mb-2 mt-6">모델 인스턴스 생성 및 구조 확인</h3>
                <div class="explanation">
                    <p>모델을 생성하고 GPU로 이동시킨 후 구조를 출력합니다. 또한 더미 데이터를 통과시켜 출력 크기가 (Batch_Size, 10)으로 올바르게 나오는지 확인합니다.</p>
                </div>
                <pre><code class="language-python">model = globals()[model_type]().to(DEVICE)
print(model)

x_batch, _ = next(iter(train_DL))
print(x_batch.shape)

model.eval()
with torch.no_grad():
    print(model(x_batch.to(DEVICE)).shape)</code></pre>
                <div class="output-label">OUTPUT (Summary)</div>
                <div class="output-block">CNN_deep(
  (conv_block1): Sequential(...)
  (Maxpool1): MaxPool2d(...)
  (conv_block2): Sequential(...)
  (Maxpool2): MaxPool2d(...)
  (conv_block3): Sequential(...)
  (Maxpool3): MaxPool2d(...)
  (classifier): Sequential(...)
)
torch.Size([64, 3, 96, 96])
torch.Size([64, 10])</div>
            </section>

            <!-- Section 7: Training -->
            <section id="training" class="card">
                <h2 class="section-title">7. 학습 (Training Loop)</h2>
                <div class="explanation">
                    <p>
                        새로운 모델을 학습시키는 경우(<code>new_model_train = True</code>), Optimizer와 Scheduler를 설정하고 <code>Train</code> 함수를 호출합니다.
                        (노트북 실행 기록상 중간에 중단되었으나, 코드는 정상적으로 작성되었습니다.)
                    </p>
                </div>
                <pre><code class="language-python">if new_model_train:
    params = [p for p in model.parameters() if p.requires_grad] # for transfer learning
    optimizer = optim.Adam(params, lr = LR, weight_decay=LAMBDA)
    scheduler = StepLR(optimizer, step_size=LR_STEP, gamma=LR_GAMMA)

    Train(model, train_DL, val_DL, criterion, optimizer, scheduler,
          EPOCH, BATCH_SIZE, save_model_path, save_history_path)</code></pre>
                <div class="output-label">OUTPUT LOG (Partial)</div>
                <div class="output-block">Epoch: 1, current_LR = 0.002
train loss: 5.32023, val loss: 2.33069 
train acc: 11.2 %, val acc: 9.2 %, time: 410 s
--------------------
Epoch: 2, current_LR = 0.002
train loss: 2.30384, val loss: 2.25753 
train acc: 11.9 %, val acc: 15.4 %, time: 413 s
...</div>
            </section>

            <!-- Section 8: History & Results -->
            <section id="history" class="card">
                <h2 class="section-title">8. 저장된 모델 로드 및 학습 결과 그래프</h2>
                <div class="explanation">
                    <p>학습이 완료되어 저장된 모델과 히스토리 파일을 로드합니다. 이를 통해 학습 과정에서의 Loss와 Accuracy 변화를 시각화합니다.</p>
                </div>
                <pre><code class="language-python">loaded = torch.load(save_model_path, map_location=DEVICE, weights_only=False)
load_model = loaded["model"]
ep = loaded["ep"]
optimizer = loaded["optimizer"]
scheduler = loaded["scheduler"]

loaded = torch.load(save_history_path, map_location=DEVICE, weights_only=False)
loss_history = loaded["loss_history"]
acc_history = loaded["acc_history"]

print(ep)
print(optimizer)
print(scheduler.step_size)
print(scheduler.gamma)</code></pre>

                <h3 class="text-lg font-semibold mb-2 mt-6">Loss & Accuracy Plot</h3>
                <div class="explanation">
                    <p>Matplotlib을 사용하여 Epoch별 Train/Validation의 Loss 감소 추이와 Accuracy 증가 추이를 그래프로 그립니다.</p>
                </div>
                <pre><code class="language-python">plt.figure()
plt.plot(range(1,EPOCH+1), loss_history["train"], label="train")
plt.plot(range(1,EPOCH+1), loss_history["val"], label="val")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Train, Val Loss")
plt.legend()
plt.grid()

plt.figure()
plt.plot(range(1,EPOCH+1), acc_history["train"], label="train")
plt.plot(range(1,EPOCH+1), acc_history["val"], label="val")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.title("Train, Val Accuracy")
plt.legend()
plt.grid()</code></pre>
            </section>

            <!-- Section 9: Test & Evaluate -->
            <section id="test" class="card">
                <h2 class="section-title">9. 테스트 및 최종 평가</h2>
                <div class="explanation">
                    <p>로드한 모델(<code>load_model</code>)을 사용하여 Test 데이터셋에 대한 최종 성능을 평가합니다. 또한 모델의 총 파라미터 개수를 확인하고, 혼동 행렬(Confusion Matrix)을 통해 클래스별 분류 성능을 상세히 분석합니다.</p>
                </div>

                <h3 class="text-lg font-semibold mb-2">Test 실행 및 파라미터 수 확인</h3>
                <pre><code class="language-python">Test(load_model, test_DL, criterion)
print(count_params(load_model))</code></pre>

                <h3 class="text-lg font-semibold mb-2 mt-6">테스트 결과 시각화 (Predictions)</h3>
                <pre><code class="language-python">Test_plot(load_model,test_DL)</code></pre>

                <h3 class="text-lg font-semibold mb-2 mt-6">Confusion Matrix</h3>
                <div class="explanation">
                    <p>모델이 어떤 클래스를 잘 맞추고, 어떤 클래스끼리 헷갈려하는지 시각적으로 확인하기 위해 Confusion Matrix를 그립니다.</p>
                </div>
                <pre><code class="language-python">confusion = get_conf(load_model, test_DL)
plot_confusion_matrix(confusion, test_DS.classes)
plt.xticks(rotation=45);</code></pre>
            </section>

        </div>
    </main>

    <!-- Footer -->
    <footer class="text-center py-8 text-gray-500 text-sm border-t border-gray-200 mt-12 bg-white">
        <p>Analysis of <code>multiclass_classification_STL10.ipynb</code></p>
        <p>&copy; 2024 Project Analysis Report</p>
    </footer>

    <!-- Prism JS for Highlighting -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>

    <!-- Sidebar Active State Script -->
    <script>
        document.addEventListener('DOMContentLoaded', () => {
            const sections = document.querySelectorAll('section');
            const navLinks = document.querySelectorAll('.nav-link');

            window.addEventListener('scroll', () => {
                let current = '';
                sections.forEach(section => {
                    const sectionTop = section.offsetTop;
                    if (scrollY >= sectionTop - 100) {
                        current = section.getAttribute('id');
                    }
                });

                navLinks.forEach(link => {
                    link.classList.remove('active');
                    if (link.getAttribute('href').includes(current)) {
                        link.classList.add('active');
                    }
                });
            });
        });
    </script>
</body>
</html>